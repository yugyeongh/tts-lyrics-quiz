import streamlit as st
import json
import re
import random
import io
import threading
import queue
from gtts import gTTS
from streamlit_webrtc import webrtc_streamer, WebRtcMode
import speech_recognition as sr
import av

# ìŠ¤íƒ€ì¼ ì„¤ì • (ì›í•˜ëŠ” CSS ìŠ¤íƒ€ì¼ ì—¬ê¸°ì— ë„£ì–´ë„ ë¨)
MAIN_STYLES = """
<style>
.question-number {
    font-size: 30px;
    font-weight: bold;
    text-align: center;
}
.icon-container {
    text-align: center;
    margin-top: 20px;
}
.loading-icon {
    font-size: 18px;
    color: gray;
}
.speaker-icon-playing {
    font-size: 40px;
    color: green;
}
</style>
"""

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ê°€ì‚¬ ë‚­ë… í€´ì¦ˆ - ê²Œì„",
    page_icon="ğŸµ",
    layout="centered"
)

st.markdown(MAIN_STYLES, unsafe_allow_html=True)

# íŠ¹ìˆ˜ë¬¸ì ì œê±°
def sanitize_filename(name):
    return re.sub(r'[\\/*?:"<>|]', "", name)

# ìƒíƒœ ì´ˆê¸°í™”
if 'remaining_songs' not in st.session_state:
    with open('./data/songs.json', 'r', encoding='utf-8') as file:
        st.session_state.remaining_songs = json.load(file)
        random.shuffle(st.session_state.remaining_songs)

if 'tts_state' not in st.session_state:
    st.session_state.tts_state = 'initial'
if 'current_audio' not in st.session_state:
    st.session_state.current_audio = None
if 'current_title' not in st.session_state:
    st.session_state.current_title = None
if 'question_number' not in st.session_state:
    st.session_state.question_number = 1
if 'button_text' not in st.session_state:
    st.session_state.button_text = "ğŸµ ë…¸ë˜ ë“£ê¸°"
if 'answer_result' not in st.session_state:
    st.session_state.answer_result = ''

# ë¬¸ì œ ë²ˆí˜¸ í‘œì‹œ
st.markdown(f'''
    <h1 class="question-number">
        <span class="number">{st.session_state.question_number}</span><span class="word">ë²ˆ</span> <span class="question">ë¬¸ì œ</span>
    </h1>
''', unsafe_allow_html=True)

# ìƒíƒœë³„ í‘œì‹œ
if st.session_state.tts_state == 'loading':
    st.markdown('''
        <div class="icon-container">
            <div class="loading-icon">
                <div class="loading-spinner"></div>
                TTS ë³€í™˜ ì¤‘...
            </div>
        </div>
    ''', unsafe_allow_html=True)
elif st.session_state.tts_state == 'playing':
    icon = "ğŸ”Š" if "ì •ë‹µ" not in st.session_state.answer_result else st.session_state.answer_result
    st.markdown(f'''
        <div class="icon-container">
            <div class="speaker-icon-playing">{icon}</div>
        </div>
    ''', unsafe_allow_html=True)

# ë²„íŠ¼ â†’ TTS ì‹œì‘
if st.button(st.session_state.button_text):
    if st.session_state.remaining_songs:
        st.session_state.tts_state = 'loading'
        st.rerun()
    else:
        st.warning("ğŸ‰ ëª¨ë“  ë…¸ë˜ë¥¼ ë‹¤ ë“¤ì—ˆìŠµë‹ˆë‹¤! í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.")

# TTS ë³€í™˜
if st.session_state.tts_state == 'loading':
    song = st.session_state.remaining_songs.pop()
    title = sanitize_filename(song['song_title'])
    lyrics = song['lyrics']
    input_text = "\n".join(lyrics) if isinstance(lyrics, list) else lyrics

    try:
        tts = gTTS(text=input_text, lang='ko')
        audio_fp = io.BytesIO()
        tts.write_to_fp(audio_fp)
        audio_fp.seek(0)

        st.session_state.current_audio = audio_fp
        st.session_state.current_title = title
        st.session_state.tts_state = 'playing'
        st.session_state.button_text = "ğŸµ ë‹¤ìŒ ë…¸ë˜ ë“£ê¸°"
        st.session_state.answer_result = ''
        st.rerun()
    except Exception as e:
        st.error(f"âŒ {title} ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.session_state.tts_state = 'initial'

# STTìš© íì™€ ì“°ë ˆë“œ
audio_queue = queue.Queue()
recognizer = sr.Recognizer()

class AudioProcessor:
    def recv(self, frame: av.AudioFrame) -> av.AudioFrame:
        pcm = frame.to_ndarray().flatten().astype("int16").tobytes()
        audio_queue.put(pcm)
        return frame

def recognize_from_mic():
    audio_data = b""
    in_answer_mode = False

    while True:
        try:
            pcm = audio_queue.get(timeout=3)
            audio_data += pcm
            if len(audio_data) > 16000 * 4:
                with sr.AudioData(audio_data, 16000, 2) as audio:
                    try:
                        text = recognizer.recognize_google(audio, language="ko-KR").lower()
                        print("ğŸ¤ ì¸ì‹ ê²°ê³¼:", text)

                        if "ì •ë‹µ" in text:
                            st.session_state.answer_result = "ğŸ¤ ì •ë‹µ ëª¨ë“œ: ì •ë‹µì„ ë§í•´ì£¼ì„¸ìš”!"
                            in_answer_mode = True
                        elif in_answer_mode:
                            if st.session_state.current_title.lower() in text:
                                st.session_state.answer_result = "ì •ë‹µì…ë‹ˆë‹¤ğŸ¤©"
                            else:
                                st.session_state.answer_result = "ì˜¤ë‹µì…ë‹ˆë‹¤ğŸš¨"
                            in_answer_mode = False
                    except:
                        pass
                audio_data = b""
        except queue.Empty:
            continue

# ë°±ê·¸ë¼ìš´ë“œ STT ì“°ë ˆë“œ ì‹¤í–‰
threading.Thread(target=recognize_from_mic, daemon=True).start()

# webrtc ì‹œì‘
webrtc_streamer(
    key="stt",
    mode=WebRtcMode.SENDONLY,
    audio_processor_factory=AudioProcessor,
    media_stream_constraints={"audio": True, "video": False},
    async_processing=True,
)

# TTS ì¬ìƒ
if st.session_state.tts_state == 'playing':
    st.audio(st.session_state.current_audio, format="audio/mp3")
    st.markdown("ğŸ™ï¸ ë§ˆì´í¬ê°€ ì¼œì ¸ ìˆìŠµë‹ˆë‹¤. 'ì •ë‹µ'ì„ ë§í•˜ë©´ ì •ë‹µì„ ì™¸ì¹  ìˆ˜ ìˆì–´ìš”!")
    if st.session_state.answer_result:
        st.markdown(f"## {st.session_state.answer_result}")

